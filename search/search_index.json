{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Kiwi Words! This website documents research on languages spoken in Aotearoa New Zealand, carried out by academics at the University of Waikato , NZ. Specifically, our projects describe and analyse te reo M\u0101ori (the indigenous language of the country) and various varieties of English spoken on the shores of Aotearoa New Zealand. Each project has a different focus and makes use of different data (all of which is collected by Waikato researchers in conjunction with our collaborators). The various tabs provide information on the different projects, their main objective, the specific team of researchers involved and arising publications or media attention. We are grateful to our funders for their generous support: GitHub Repository Our Github repository provides relevant code for each project (e.g. for collecting, cleaning and analysing the data). Get in touch If you would like to get in touch with us, please email Andreea Calude for general research inquiries (andreea@waikato.ac.nz) and David Trye for website admin and data downloading inquiries (dtrye@waikato.ac.nz). Thank you for visiting our website!","title":"Home"},{"location":"#welcome-to-kiwi-words","text":"This website documents research on languages spoken in Aotearoa New Zealand, carried out by academics at the University of Waikato , NZ. Specifically, our projects describe and analyse te reo M\u0101ori (the indigenous language of the country) and various varieties of English spoken on the shores of Aotearoa New Zealand. Each project has a different focus and makes use of different data (all of which is collected by Waikato researchers in conjunction with our collaborators). The various tabs provide information on the different projects, their main objective, the specific team of researchers involved and arising publications or media attention. We are grateful to our funders for their generous support:","title":"Welcome to Kiwi Words!"},{"location":"#github-repository","text":"Our Github repository provides relevant code for each project (e.g. for collecting, cleaning and analysing the data).","title":"GitHub Repository"},{"location":"#get-in-touch","text":"If you would like to get in touch with us, please email Andreea Calude for general research inquiries (andreea@waikato.ac.nz) and David Trye for website admin and data downloading inquiries (dtrye@waikato.ac.nz). Thank you for visiting our website!","title":"Get in touch"},{"location":"corpus/","text":"Loanword Twitter Corpus The M\u0101ori Loanword Twitter Corpus ( MLT Corpus ) is a diachronic corpus of nearly 3 million New Zealand English tweets, posted between 2008 and 2018. The data was collected by extracting tweets containing one or more terms from a list of 77 M\u0101ori words and phrases. We then used computational machine learning methods to clean up the raw data, because many of the tweets were not relevant to a New Zealand English context (for instance, the loanword Moana , meaning sea, is commonly used to refer to the Disney film/princess). The corpus consists of three key components: Raw Corpus : The original dataset, which includes many irrelevant (non-New Zealand English) tweets. Labelled Corpus : 3,685 tweets that were manually labelled as \"relevant\" or \"irrelevant\" and used as training data for our model. Processed Corpus : The final version of the corpus, containing only tweets that the model classified as relevant. Building the MLT Corpus Below is a visual representation of the steps involved in building the corpus. For further information, see our paper . Summary Statistics This table shows key stats for the different components of the MLT Corpus: Description Raw Corpus V2* Labelled Corpus Processed Corpus V2* Tokens (words) 70,964,941 49,477 46,827,631 Tweets 4,559,105 2,495 2,880,211 Tweeters (authors) 1,839,707 1,866 1,226,109 *Please note that these statistics differ from what is stated in the paper, because we later refined our classifier, opting for a Naive Bayes Multinomial model that considered both unigrams and bigrams. Word Vectors The visualisations below were obtained after training Word2Vec embeddings on the M\u0101ori Loanword Twitter (MLT) Corpus. Hyper-parameters were optimised by minimising the median ranking of a list of given word pairs. The vectors are projected into two-dimensional space using the t-SNE method. Whakapapa Aroha Haka Kia Kaha Kia Ora Matariki Wahine Whakapapa Download the MLT Corpus Click to download the MLT Corpus . Citing the MLT Corpus If you use the MLT corpus, please cite the following paper - Trye, D., Calude, A., Bravo-Marquez, F., Keegan, T. T. (2019). M\u0101ori loanwords: A corpus of New Zealand English tweets . In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop , pp. 136\u2013142. Florence, Italy: Association for Computational Linguistics. doi:10.18653/v1/P19-2018. Team David Trye Andreea Calude Te Taka Keegan Nicole Chan External Collaborators - Felipe Bravo Marquez , University of Chile Funding We graciously acknowledge the generous support of - Marsden Fund, Royal Society of New Zealand","title":"Loanwords"},{"location":"corpus/#loanword-twitter-corpus","text":"The M\u0101ori Loanword Twitter Corpus ( MLT Corpus ) is a diachronic corpus of nearly 3 million New Zealand English tweets, posted between 2008 and 2018. The data was collected by extracting tweets containing one or more terms from a list of 77 M\u0101ori words and phrases. We then used computational machine learning methods to clean up the raw data, because many of the tweets were not relevant to a New Zealand English context (for instance, the loanword Moana , meaning sea, is commonly used to refer to the Disney film/princess). The corpus consists of three key components: Raw Corpus : The original dataset, which includes many irrelevant (non-New Zealand English) tweets. Labelled Corpus : 3,685 tweets that were manually labelled as \"relevant\" or \"irrelevant\" and used as training data for our model. Processed Corpus : The final version of the corpus, containing only tweets that the model classified as relevant.","title":"Loanword Twitter Corpus"},{"location":"corpus/#building-the-mlt-corpus","text":"Below is a visual representation of the steps involved in building the corpus. For further information, see our paper .","title":"Building the MLT Corpus"},{"location":"corpus/#summary-statistics","text":"This table shows key stats for the different components of the MLT Corpus: Description Raw Corpus V2* Labelled Corpus Processed Corpus V2* Tokens (words) 70,964,941 49,477 46,827,631 Tweets 4,559,105 2,495 2,880,211 Tweeters (authors) 1,839,707 1,866 1,226,109 *Please note that these statistics differ from what is stated in the paper, because we later refined our classifier, opting for a Naive Bayes Multinomial model that considered both unigrams and bigrams.","title":"Summary Statistics"},{"location":"corpus/#word-vectors","text":"The visualisations below were obtained after training Word2Vec embeddings on the M\u0101ori Loanword Twitter (MLT) Corpus. Hyper-parameters were optimised by minimising the median ranking of a list of given word pairs. The vectors are projected into two-dimensional space using the t-SNE method. Whakapapa Aroha Haka Kia Kaha Kia Ora Matariki Wahine Whakapapa","title":"Word Vectors"},{"location":"corpus/#download-the-mlt-corpus","text":"Click to download the MLT Corpus .","title":"Download the MLT Corpus"},{"location":"corpus/#citing-the-mlt-corpus","text":"If you use the MLT corpus, please cite the following paper - Trye, D., Calude, A., Bravo-Marquez, F., Keegan, T. T. (2019). M\u0101ori loanwords: A corpus of New Zealand English tweets . In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop , pp. 136\u2013142. Florence, Italy: Association for Computational Linguistics. doi:10.18653/v1/P19-2018.","title":"Citing the MLT Corpus"},{"location":"corpus/#team","text":"David Trye Andreea Calude Te Taka Keegan Nicole Chan External Collaborators - Felipe Bravo Marquez , University of Chile","title":"Team"},{"location":"corpus/#funding","text":"We graciously acknowledge the generous support of - Marsden Fund, Royal Society of New Zealand","title":"Funding"},{"location":"hh_corpus/","text":"Hybrid Hashtag Sub-Corpus The Hybrid Hashtag Sub-Corpus ( HH Corpus ) is a subset of tweets in the MLT corpus containing hashtags made up of M\u0101ori and English words (so-called \"hybrid hashtags\"). There are 81 hybrid hashtags in this dataset, used in 5,684 tweets and posted to Twitter by 3,771 distinct users. Download the HH Corpus Click to download the HH Sub-Corpus . Citing the HH Corpus If you use the Hybrid Hashtag Corpus, please cite the following paper - Trye, D., Calude, A. S., Bravo-Marquez, F., Keegan, T. T. (2020). Hybrid Hashtags: #YouKnowYoureAKiwiWhen Your Tweet Contains M\u0101ori and English . Front. Artif. Intell. 3:15. doi:10.3389/frai.2020.00015. Team David Trye Andreea Calude Te Taka Keegan External Collaborators - Felipe Bravo Marquez , University of Chile Funding We graciously acknowledge the generous support of: - Marsden Fund, Royal Society of New Zealand","title":"Hybrid Hashtags"},{"location":"hh_corpus/#hybrid-hashtag-sub-corpus","text":"The Hybrid Hashtag Sub-Corpus ( HH Corpus ) is a subset of tweets in the MLT corpus containing hashtags made up of M\u0101ori and English words (so-called \"hybrid hashtags\"). There are 81 hybrid hashtags in this dataset, used in 5,684 tweets and posted to Twitter by 3,771 distinct users.","title":"Hybrid Hashtag Sub-Corpus"},{"location":"hh_corpus/#download-the-hh-corpus","text":"Click to download the HH Sub-Corpus .","title":"Download the HH Corpus"},{"location":"hh_corpus/#citing-the-hh-corpus","text":"If you use the Hybrid Hashtag Corpus, please cite the following paper - Trye, D., Calude, A. S., Bravo-Marquez, F., Keegan, T. T. (2020). Hybrid Hashtags: #YouKnowYoureAKiwiWhen Your Tweet Contains M\u0101ori and English . Front. Artif. Intell. 3:15. doi:10.3389/frai.2020.00015.","title":"Citing the HH Corpus"},{"location":"hh_corpus/#team","text":"David Trye Andreea Calude Te Taka Keegan External Collaborators - Felipe Bravo Marquez , University of Chile","title":"Team"},{"location":"hh_corpus/#funding","text":"We graciously acknowledge the generous support of: - Marsden Fund, Royal Society of New Zealand","title":"Funding"},{"location":"maori_english/","text":"M\u0101ori English Corpus This project aims to document the fastest growing variety of English spoken currently in Aotearoa New Zealand, M\u0101ori English. We have recorded and manually transcribed 43 spontaneous dyadic conversations from 49 speakers of M\u0101ori English located in and around the Waikato region. Because M\u0101ori English distinguishes itself from related varieties of English in relative (rather than absolute) frequencies of various features, it has to date been difficult to clearly capture the nature of this variety. The corpus is currently being analysed and our hope is to use this data to increase understanding of M\u0101ori English. Team PI Andreea S. Calude H\u0113mi Whaanga External Collaborators - Alex D\u2019Arcy - Anita Szakay Funding We graciously acknowledge the generous support of - The University of Waikato Medium SIF Fund","title":"M\u0101ori English"},{"location":"maori_english/#maori-english-corpus","text":"This project aims to document the fastest growing variety of English spoken currently in Aotearoa New Zealand, M\u0101ori English. We have recorded and manually transcribed 43 spontaneous dyadic conversations from 49 speakers of M\u0101ori English located in and around the Waikato region. Because M\u0101ori English distinguishes itself from related varieties of English in relative (rather than absolute) frequencies of various features, it has to date been difficult to clearly capture the nature of this variety. The corpus is currently being analysed and our hope is to use this data to increase understanding of M\u0101ori English.","title":"M\u0101ori English Corpus"},{"location":"maori_english/#team","text":"PI Andreea S. Calude H\u0113mi Whaanga External Collaborators - Alex D\u2019Arcy - Anita Szakay","title":"Team"},{"location":"maori_english/#funding","text":"We graciously acknowledge the generous support of - The University of Waikato Medium SIF Fund","title":"Funding"},{"location":"nze_lexicon/","text":"NZE Lexicon This project will investigate knowledge of New Zealand English words (both native English words and words borrowed from te reo Ma\u0304ori) believed to be in common use in NZ. We will norm a set of pictures combining a subset of existing pictures normed with other languages including two separate English varieties. The pictures include a set of purpose-drawn illustrations denoting concepts commonly borrowed from te reo Ma\u0304ori. See some pictures from our set below: Credit for images: Scott Pearson at Visual Evolution We will then use these materials to test New Zealand children\u2019s receptive vocabulary knowledge and cultural sensitivity towards the concepts shown. Team PI Andreea S. Calude H\u0113mi Whaanga External Collaborators - Eline Zenner , KU Leuven - Laura Rosseel , Vrije Universiteit Brussel Publications Publications coming soon - watch this space!","title":"NZE Lexicon"},{"location":"nze_lexicon/#nze-lexicon","text":"This project will investigate knowledge of New Zealand English words (both native English words and words borrowed from te reo Ma\u0304ori) believed to be in common use in NZ. We will norm a set of pictures combining a subset of existing pictures normed with other languages including two separate English varieties. The pictures include a set of purpose-drawn illustrations denoting concepts commonly borrowed from te reo Ma\u0304ori. See some pictures from our set below: Credit for images: Scott Pearson at Visual Evolution We will then use these materials to test New Zealand children\u2019s receptive vocabulary knowledge and cultural sensitivity towards the concepts shown.","title":"NZE Lexicon"},{"location":"nze_lexicon/#team","text":"PI Andreea S. Calude H\u0113mi Whaanga External Collaborators - Eline Zenner , KU Leuven - Laura Rosseel , Vrije Universiteit Brussel","title":"Team"},{"location":"nze_lexicon/#publications","text":"Publications coming soon - watch this space!","title":"Publications"},{"location":"rmt_corpus/","text":"M\u0101ori Twitter Corpus The Reo M\u0101ori Twitter (RMT) Corpus is a collection of 79,018 te reo M\u0101ori tweets, designed for linguistic analysis and to help in the development of new Natural Language Processing (NLP) resources for the M\u0101ori community. The corpus captures output from 2,302 users, including a mixture of personal and institutional accounts. These users were identified via Prof. Kevin Scannell's Indigenous Tweets website . Download the RMT Corpus The tweets and user metadata in the RMT Corpus can be hydrated (downloaded from Twitter) using the code provided. The source code is adapted from Twitter's sample code for API v2 endpoints. Note: Some tweets in the corpus are no longer publicly available and, as such, cannot be downloaded. Please email dtrye@waikato.ac.nz if you would like access to the complete dataset, including additional metadata mentioned in our paper. The speed at which you can download the corpus depends on the rate limit for your Twitter developer account (e.g. 300 or 900 requests per 15-minute window). If you exceed the allocated limit, a 429 'Too many requests' error will be returned. Apply for a Twitter developer account if you do not have one already. Ensure that Python 3 is installed on your machine. The code for hydrating the corpus uses requests==2.24.0 , which in turn uses requests-oauthlib==1.3.0 . You can install these packages as follows: pip install requests pip install requests-oauthlib Download and extract all files in the rmt-v1 folder. This folder contains a file called rmt-corpus-v1.csv , which has the tweet IDs and selected metadata, as well as two Python scripts for downloading and formatting the data (namely, get_tweets_with_bearer_token.py and json_to_tsv.py ). Configure your API bearer token by running the following command in the terminal: export 'BEARER_TOKEN'=' your_bearer_token ' Run get_tweets_with_bearer_token.py from the terminal. python get_tweets_with_bearer_token.py output.json This will download the corpus in batches of 100 tweets. If you use the default settings, the script will take roughly 45 minutes to run, as it will attempt to download 30,000 tweets (300 requests x 100 tweets) every 15 minutes. The resulting file, output.json , is only pseudo-JSON (each batch is separated by a line in the form \"Batch X , Code Y \", where X and Y are numbers). Run json_to_tsv.py to convert the output file to TSV format. python json_to_tsv.py This script will produce a file called rmt-corpus-final.csv , which you can then open in a spreadsheet application. Tweet text is formatted consistently (special characters are removed, any HTML is decoded, and user mentions and links are standardised). The tweets are also supplemented with metadata from the original rmt-corpus-v1.csv file. A description of the variables in each of the CSV files is given below. Data Description: rmt-corpus-v1.csv The following information (where known) is supplied in rmt-corpus-v1.csv , even if the tweet is no longer available on Twitter. Data Column Description id Twitter's unique identifier for the tweet. You can search for a tweet online by visiting twitter.com/user/status/XXX , where XXX is the tweet's ID. num_maori_words The number of M\u0101ori words in the tweet. total_words The total number of words in the tweet. percent_maori The percentage of M\u0101ori text detected in the tweet (= num_maori_words / total_words *100). favourites The number of favourites (likes, retweets quotes) that the given tweet received. reply_count The number of replies that the given tweet received. user.alias An alias for the author of the tweet in the form T X , where X represents the user\u2019s ranking based on their total number of tweets in the corpus ( user.num_tweets ). user.status The account status (as of Decemeber 2020) of the user who wrote the tweet: 'active', 'protected', 'suspended' or 'not found'. user.followers The user's number of followers (as of December 2020). user.friends The number of accounts that the user follows (as of December 2020). user.num_tweets The total number of tweets in the corpus that were written by this user. user.region The user's location, based on self-reported information. Where possible, the data has been aggregated into New Zealand regions and names of foreign countries. year The year the tweet was written (between 2007 and 2020). Data Description: rmt-corpus-final.csv If the tweet is still publicly available on Twitter, the following variables will appear alongside those mentioned above. Missing values are indicated with 'None': Data Column Description text The tweet content, with consistent formatting applied (special characters stripped, user mentions and links standardised). conversation_id The ID for the conversation that the tweet is part of. in_reply_to_user_id If the tweet is written in reply to another, this is the ID of the user who who wrote the original tweet. author_id Twitter's unique identifier for the user who wrote the tweet. created_at The timestamp when the tweet was posted, in the format YYYY-MM-DDTHH:mm:ss.000Z . lang The two-letter code representing the language that the tweet was (erroneously) classified as (NOT M\u0101ori, as the API does not support te reo). source The device or third-party application from which the tweet was posted (e.g. 'Twitter Web Client', 'Twitter for iPhone'). error The reason why the tweet could not be downloaded, if there was an error ('Authorization Error', 'Not Found Error', 'None'). Other Resources Code for cleaning and analysing the RMT Corpus is available on the project GitHub repository . You can download a wordlist with frequencies for all words and hashtags in the corpus. Citing the RMT Corpus If you use the RMT corpus, please cite the following paper - 'Building a Corpus of M\u0101ori Language Tweets' by Trye et al. (full reference coming soon!). Team David Trye Te Taka Keegan Paora Mato Mark Apperley Tamahau Brown External Collaborators - Te Hiku Media , NZ - Kevin Scannell , Saint Louis University Funding We graciously acknowledge the generous support of - Ng\u0101 Pae o te M\u0101ramatanga - The University of Waikato The information on this page was last checked in April 2021. Please let us know if you notice any errors in the code and/or instructions. As of 12 April 2021, 72,575 tweets ( 91.85% of the RMT Corpus) could be successfully downloaded from Twitter.","title":"M\u0101ori Corpus"},{"location":"rmt_corpus/#maori-twitter-corpus","text":"The Reo M\u0101ori Twitter (RMT) Corpus is a collection of 79,018 te reo M\u0101ori tweets, designed for linguistic analysis and to help in the development of new Natural Language Processing (NLP) resources for the M\u0101ori community. The corpus captures output from 2,302 users, including a mixture of personal and institutional accounts. These users were identified via Prof. Kevin Scannell's Indigenous Tweets website .","title":"M\u0101ori Twitter Corpus"},{"location":"rmt_corpus/#download-the-rmt-corpus","text":"The tweets and user metadata in the RMT Corpus can be hydrated (downloaded from Twitter) using the code provided. The source code is adapted from Twitter's sample code for API v2 endpoints. Note: Some tweets in the corpus are no longer publicly available and, as such, cannot be downloaded. Please email dtrye@waikato.ac.nz if you would like access to the complete dataset, including additional metadata mentioned in our paper. The speed at which you can download the corpus depends on the rate limit for your Twitter developer account (e.g. 300 or 900 requests per 15-minute window). If you exceed the allocated limit, a 429 'Too many requests' error will be returned. Apply for a Twitter developer account if you do not have one already. Ensure that Python 3 is installed on your machine. The code for hydrating the corpus uses requests==2.24.0 , which in turn uses requests-oauthlib==1.3.0 . You can install these packages as follows: pip install requests pip install requests-oauthlib Download and extract all files in the rmt-v1 folder. This folder contains a file called rmt-corpus-v1.csv , which has the tweet IDs and selected metadata, as well as two Python scripts for downloading and formatting the data (namely, get_tweets_with_bearer_token.py and json_to_tsv.py ). Configure your API bearer token by running the following command in the terminal: export 'BEARER_TOKEN'=' your_bearer_token ' Run get_tweets_with_bearer_token.py from the terminal. python get_tweets_with_bearer_token.py output.json This will download the corpus in batches of 100 tweets. If you use the default settings, the script will take roughly 45 minutes to run, as it will attempt to download 30,000 tweets (300 requests x 100 tweets) every 15 minutes. The resulting file, output.json , is only pseudo-JSON (each batch is separated by a line in the form \"Batch X , Code Y \", where X and Y are numbers). Run json_to_tsv.py to convert the output file to TSV format. python json_to_tsv.py This script will produce a file called rmt-corpus-final.csv , which you can then open in a spreadsheet application. Tweet text is formatted consistently (special characters are removed, any HTML is decoded, and user mentions and links are standardised). The tweets are also supplemented with metadata from the original rmt-corpus-v1.csv file. A description of the variables in each of the CSV files is given below.","title":"Download the RMT Corpus"},{"location":"rmt_corpus/#data-description-rmt-corpus-v1csv","text":"The following information (where known) is supplied in rmt-corpus-v1.csv , even if the tweet is no longer available on Twitter. Data Column Description id Twitter's unique identifier for the tweet. You can search for a tweet online by visiting twitter.com/user/status/XXX , where XXX is the tweet's ID. num_maori_words The number of M\u0101ori words in the tweet. total_words The total number of words in the tweet. percent_maori The percentage of M\u0101ori text detected in the tweet (= num_maori_words / total_words *100). favourites The number of favourites (likes, retweets quotes) that the given tweet received. reply_count The number of replies that the given tweet received. user.alias An alias for the author of the tweet in the form T X , where X represents the user\u2019s ranking based on their total number of tweets in the corpus ( user.num_tweets ). user.status The account status (as of Decemeber 2020) of the user who wrote the tweet: 'active', 'protected', 'suspended' or 'not found'. user.followers The user's number of followers (as of December 2020). user.friends The number of accounts that the user follows (as of December 2020). user.num_tweets The total number of tweets in the corpus that were written by this user. user.region The user's location, based on self-reported information. Where possible, the data has been aggregated into New Zealand regions and names of foreign countries. year The year the tweet was written (between 2007 and 2020).","title":"Data Description: rmt-corpus-v1.csv"},{"location":"rmt_corpus/#data-description-rmt-corpus-finalcsv","text":"If the tweet is still publicly available on Twitter, the following variables will appear alongside those mentioned above. Missing values are indicated with 'None': Data Column Description text The tweet content, with consistent formatting applied (special characters stripped, user mentions and links standardised). conversation_id The ID for the conversation that the tweet is part of. in_reply_to_user_id If the tweet is written in reply to another, this is the ID of the user who who wrote the original tweet. author_id Twitter's unique identifier for the user who wrote the tweet. created_at The timestamp when the tweet was posted, in the format YYYY-MM-DDTHH:mm:ss.000Z . lang The two-letter code representing the language that the tweet was (erroneously) classified as (NOT M\u0101ori, as the API does not support te reo). source The device or third-party application from which the tweet was posted (e.g. 'Twitter Web Client', 'Twitter for iPhone'). error The reason why the tweet could not be downloaded, if there was an error ('Authorization Error', 'Not Found Error', 'None').","title":"Data Description: rmt-corpus-final.csv"},{"location":"rmt_corpus/#other-resources","text":"Code for cleaning and analysing the RMT Corpus is available on the project GitHub repository . You can download a wordlist with frequencies for all words and hashtags in the corpus.","title":"Other Resources"},{"location":"rmt_corpus/#citing-the-rmt-corpus","text":"If you use the RMT corpus, please cite the following paper - 'Building a Corpus of M\u0101ori Language Tweets' by Trye et al. (full reference coming soon!).","title":"Citing the RMT Corpus"},{"location":"rmt_corpus/#team","text":"David Trye Te Taka Keegan Paora Mato Mark Apperley Tamahau Brown External Collaborators - Te Hiku Media , NZ - Kevin Scannell , Saint Louis University","title":"Team"},{"location":"rmt_corpus/#funding","text":"We graciously acknowledge the generous support of - Ng\u0101 Pae o te M\u0101ramatanga - The University of Waikato The information on this page was last checked in April 2021. Please let us know if you notice any errors in the code and/or instructions. As of 12 April 2021, 72,575 tweets ( 91.85% of the RMT Corpus) could be successfully downloaded from Twitter.","title":"Funding"}]}